{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use localpdb to create a dataset for machine learning purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within this notebook we demonstrate the procedures used to derive the dataset used to train a coiled-coil domain prediction method - DeepCoil (<a href=\"https://github.com/labstructbioinf/DeepCoil\">Repository</a>, <a href=\"https://academic.oup.com/bioinformatics/article/35/16/2790/5270664\">Paper</a>). The steps described here can be easily adapted to any other task of interest, e.g. secondary structure prediction, other motif detection etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from localpdb import PDB\n",
    "\n",
    "\n",
    "NCBI_PATH='/opt/apps/ncbi-blast+/bin/'\n",
    "NP = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_socket_to_seqres(pdb_chain, socket_data):\n",
    "    \"\"\"\n",
    "    Calculate mapping from the SOCKET (structural data) to SEQRES (sequence data)\n",
    "    \"\"\"\n",
    "    pdb_id, chain_id = pdb_chain.split('_')\n",
    "    try:\n",
    "        cc_residues = {str(res): 1 for cc in socket_data.values() \n",
    "                       for indice in cc['indices'].values() \n",
    "                       for res in range(int(indice['start']), int(indice['end'])+1) \n",
    "                       if indice['chain'] == chain_id}\n",
    "        \n",
    "        cc_heptads = {str(res): hept for cc in socket_data.values() \n",
    "                      for indice, heptads in zip(cc['indices'].values(), cc['heptads'].values()) \n",
    "                      for res, hept in zip(range(int(indice['start']), int(indice['end'])+1), heptads) \n",
    "                      if indice['chain'] == chain_id}\n",
    "    except KeyError:\n",
    "        cc_residues = {}\n",
    "        cc_heptads = {}\n",
    "    try:\n",
    "        presence_mapping = lpdb.map_pdb_feat_to_seqres(cc_residues, pdb_chain)\n",
    "        heptad_mapping = lpdb.map_pdb_feat_to_seqres(cc_heptads, pdb_chain)\n",
    "    except ValueError:\n",
    "        return ['0', '0']\n",
    "    return (''.join([str(feat) for feat in presence_mapping]), \n",
    "            ''.join([str(feat) for feat in heptad_mapping]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_seq(seq):\n",
    "    \"\"\"\n",
    "    Corrects seqres sequence to map non-std residues to 'X' - this fixes biopython aligner weird behaviour\n",
    "    :param seq: input sequence\n",
    "    :return: corrected sequence with non-std residues changed to 'X'\n",
    "    \"\"\"\n",
    "    letters = set(list('ACDEFGHIKLMNPQRSTVWYX'))\n",
    "    corr_seq = ''.join([aa if aa in letters else 'X' for aa in seq])\n",
    "    return corr_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load localpdb and plugins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpdb = PDB(db_path='/home/db/localpdb', plugins=['Socket', 'PDBSeqresMapper', 'PDBClustering'], version=20210716)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded localpdb with 176175 structures and 603869 chains\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lpdb.load_clustering_data(redundancy='100')\n",
    "lpdb.load_clustering_data(redundancy='50')\n",
    "print(f'Loaded localpdb with {len(lpdb.entries)} structures and {len(lpdb.chains)} chains\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load test set data used in the original DeepCoil paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1 = pd.read_csv('data/raw/deepcoil_test1.csv', index_col=0)\n",
    "df_test2 = pd.read_csv('data/raw/deepcoil_test2.csv', index_col=0)\n",
    "test1_idx = set(df_test1.index)\n",
    "test2_idx = set(df_test2.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if all entries from both DeepCoil test sets are still in PDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 1 entries from test_set1 - no longer available in PDB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "diff_idx1 = test1_idx - set(lpdb.chains.index)\n",
    "diff_idx2 = test2_idx - set(lpdb.chains.index)\n",
    "\n",
    "if len(diff_idx1) > 0:\n",
    "    print(f'Removing {len(diff_idx1)} entries from test_set1 - no longer available in PDB\\n')\n",
    "    test1_idx -= diff_idx1\n",
    "\n",
    "if len(diff_idx2) > 0:\n",
    "    print(f'Removing {len(diff_idx2)} entries from test_set2 - no longer available in PDB\\n')\n",
    "    test2_idx -= diff_idx2\n",
    "    \n",
    "test_idx = test1_idx | test2_idx\n",
    "test_pdb = {pdb_chain.split('_')[0] for pdb_chain in test_idx}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter out NMR structures, structures with resolution below 4 angstroms, and with sequence length below 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering by method, resolution and sequence length...\n",
      "Remaining: 150623 structures and 386570 chains\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lpdb.entries = lpdb.entries[lpdb.entries['method'] != 'NMR']\n",
    "lpdb.entries = lpdb.entries[lpdb.entries['resolution'] <= 4.0]\n",
    "lpdb.chains = lpdb.chains[lpdb.chains['sequence'].str.len() >= 20]\n",
    "lpdb.chains = lpdb.chains[lpdb.chains.index.isin(list(lpdb._mapping_dict.keys()))]\n",
    "\n",
    "print('Filtering by method, resolution and sequence length...')\n",
    "print(f'Remaining: {len(lpdb.entries)} structures and {len(lpdb.chains)} chains\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if all entries from both DeepCoil test sets have PDB<->SEQRES mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 54 entries from test_set1 - no valid mapping\n",
      "\n",
      "Removing 9 entries from test_set2 - no valid mapping\n",
      "\n"
     ]
    }
   ],
   "source": [
    "diff_idx1 = test1_idx - set(lpdb.chains.index)\n",
    "diff_idx2 = test2_idx - set(lpdb.chains.index)\n",
    "\n",
    "if len(diff_idx1) > 0:\n",
    "    print(f'Removing {len(diff_idx1)} entries from test_set1 - no valid mapping\\n')\n",
    "    test1_idx -= diff_idx1\n",
    "\n",
    "if len(diff_idx2) > 0:\n",
    "    print(f'Removing {len(diff_idx2)} entries from test_set2 - no valid mapping\\n')\n",
    "    test2_idx -= diff_idx2\n",
    "    \n",
    "test_idx = test1_idx | test2_idx\n",
    "test_pdb = {pdb_chain.split('_')[0] for pdb_chain in test_idx}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter out identical sequences (select representative with best resolution)  - leave entries from the test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering identical entries...\n",
      "Remaining: 70447 structures and 78537 chains\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nr_idx = set(lpdb.chains.groupby(by='clust-100')['resolution'].idxmin())\n",
    "lpdb.chains = lpdb.chains.loc[(nr_idx | test_idx)]\n",
    "lpdb.chains = lpdb.chains.sort_index()\n",
    "\n",
    "print('Filtering identical entries...')\n",
    "print(f'Remaining: {len(lpdb.entries)} structures and {len(lpdb.chains)} chains\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label residues based on the SOCKET data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "socket_data_74_overlap = lpdb.get_socket_dict(cutoff='7.4', method='overlap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "socket_74_labels = {pdb_chain: map_socket_to_seqres(pdb_chain, socket_data_74_overlap.get(pdb_chain.split('_')[0], {})) \n",
    "             for pdb_chain in lpdb.chains.index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpdb.chains['socket_74_label'] = lpdb.chains.index.map(lambda x: socket_74_labels[x][0])\n",
    "lpdb.chains['socket_74_heptads'] = lpdb.chains.index.map(lambda x: socket_74_labels[x][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dump updated test sets to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1 = pd.merge(df_test1, lpdb.chains.loc[test1_idx, ['socket_74_label', 'socket_74_heptads']],\n",
    "                    left_index=True, right_index=True)\n",
    "\n",
    "df_test2 = pd.merge(df_test2, lpdb.chains.loc[test2_idx, ['socket_74_label', 'socket_74_heptads']],\n",
    "                    left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving updated test set CSVs\n"
     ]
    }
   ],
   "source": [
    "print('Saving updated test set CSVs')\n",
    "df_test1.to_csv('data/dc-test1.csv')\n",
    "df_test2.to_csv('data/dc-test2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate blast db from test set entries to query with the remaining chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('calc/psiblast/dc-db.fas', 'w')\n",
    "for id_, seq in lpdb.chains.loc[test_idx].sequence.iteritems():\n",
    "    f.write(f'>{id_}\\n{seq}\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('calc/psiblast/')\n",
    "os.system(f'{NCBI_PATH}/makeblastdb -in dc-db.fas -dbtype prot')\n",
    "os.chdir('./../../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove test set entries from lpdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpdb.chains = lpdb.chains[~lpdb.chains.index.isin(test_idx)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query the rest of the sequences against the test set and select only those which are below 30% similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('calc/psiblast/dc-query.fas', 'w')\n",
    "for id_, seq in lpdb.chains.sequence.iteritems():\n",
    "    f.write(f'>{id_}\\n{seq}\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating similarity of the PDB sequences against the test sequences...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating similarity of the PDB sequences against the test sequences...\\n\")\n",
    "os.chdir('calc/psiblast/')\n",
    "os.system(f'{NCBI_PATH}/psiblast -query dc-query.fas -db dc-db.fas -outfmt \"6 qseqid sseqid pident qcovs evalue\" ' \\\n",
    "          f'-evalue 1e-2 -num_threads {NP} -max_target_seqs 2 > dc-query.csv')\n",
    "os.chdir('./../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "redundant_df = pd.read_csv('calc/psiblast/dc-query.csv', sep='\\s+', header=None, \n",
    "                           names=['qid','sid','ident', 'cov','evalue'])\n",
    "redundant_df['w_ident'] = redundant_df['ident'] * redundant_df['cov'] / 100\n",
    "redundant_idx = set(redundant_df[(redundant_df['ident'] > 30) & (redundant_df['cov'] > 50)].qid.values)\n",
    "lpdb.chains = lpdb.chains[~lpdb.chains.index.isin(redundant_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing entries similar to entries in DeepCoil test set...\n",
      "Remaining: 66535 structures and 74076 chains\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Removing entries similar to entries in DeepCoil test set...')\n",
    "print(f'Remaining: {len(lpdb.entries)} structures and {len(lpdb.chains)} chains\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limit sequence redundancy to 50% in train set, select cluster representatives with highest CC residues fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpdb.chains['cc_frac'] = lpdb.chains['socket_74_label'].apply(lambda x: 1 - x.count('0')/len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limiting redundancy to 50%...\n",
      "Remaining: 32390 structures and 35189 chains\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx = lpdb.chains.groupby(by='clust-50')['cc_frac'].idxmax()\n",
    "lpdb.chains = lpdb.chains.loc[idx]\n",
    "print('Limiting redundancy to 50%...')\n",
    "print(f'Remaining: {len(lpdb.entries)} structures and {len(lpdb.chains)} chains\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive entries: 4019, frac=0.11421182755974879\n"
     ]
    }
   ],
   "source": [
    "pos_entries = len(lpdb.chains[lpdb.chains['cc_frac'] > 0])\n",
    "pos_entries_frac = len(lpdb.chains[lpdb.chains['cc_frac'] > 0]) / len(lpdb.chains)\n",
    "\n",
    "print(f'Positive entries: {pos_entries}, frac={pos_entries_frac}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive tokens: 181723, frac=0.018116988833092568\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokens = [int(label) for entry in lpdb.chains.socket_74_label.str.cat() for label in entry]\n",
    "print(f'Positive tokens: {tokens.count(1)}, frac={tokens.count(1)/len(tokens)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct noncanonical aa's in sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpdb.chains['sequence'] = lpdb.chains['sequence'].apply(corr_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "lpdb.chains.to_csv('data/dc-train.csv')\n",
    "print('DONE!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
