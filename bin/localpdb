#! /usr/bin/env python3
import os
import argparse
import logging
import sys
import shutil
import socket
import yaml
import ftplib
from tqdm import tqdm
from pathlib import Path
from localpdb import PDBVersioneer, PDBDownloader
from localpdb.utils.os import create_directory, setup_logging_handlers, clean_exit
from localpdb.utils.config import load_remote_source, Config


def get_params():
    # Parse arguments
    parser = argparse.ArgumentParser(description='localpdb setup/update script')
    parser.add_argument('-db_path', help='Path to store localpdb database', required=True, metavar='DB_PATH')
    parser.add_argument('-plugins', help='Names of plugins to set up', metavar='PLUGINS', nargs='+',
                        default=[])
    parser.add_argument('-mirror', help='''PDB mirror used to download the protein structures.
    Valid options are \'rcsb\' (RCSB PDB - US), \'pdbe\' (PDBe - UK) or \'pdbj\' (PDBj - Japan)''',
                        default='rcsb', metavar='MIRROR', choices=['rcsb', 'pdbe', 'pdbj'])
    parser.add_argument('--update', help='Update existing localpdb database', action='store_true')
    parser.add_argument('--fetch_pdb', help='Download the protein structures in the PDB format', action='store_true')
    parser.add_argument('--fetch_cif', help='Download the protein structures in the mmCIF format', action='store_true')

    # Add optional arguments to manually define PDB mirror (these options override the mirror definition from -mirror)
    # Used mostly for testing purposes.
    parser.add_argument('-tmp_path', help=argparse.SUPPRESS, default='/tmp/')
    parser.add_argument('-ftp_url', help=argparse.SUPPRESS)
    parser.add_argument('-rsync_url', help=argparse.SUPPRESS)
    parser.add_argument('-rsync_opts', help=argparse.SUPPRESS)
    parser.add_argument('-clust_url', help=argparse.SUPPRESS)
    args = parser.parse_args()
    args.db_path = Path(os.path.abspath(args.db_path))
    if args.update and any([args.fetch_pdb, args.fetch_cif]):
        print('\nOptions \'--update\' and any of the (\'--fetch_pdb\', \'--fetch_cif\') are mutually exclusive!\n')
        parser.print_help()
        sys.exit(1)
    return args

def download(args, mode='', clean=True):
    pdbd = PDBDownloader(db_path=args.db_path, version=args.current_remote_version, config=args.remote_source,
                         remove_unsuccessful=clean)
    pdbd.set_lock()
    if mode == 'files':
        with clean_exit(callback=pdbd.clean_unsuccessful):
            file_types = ['entries', 'entries_type', 'bundles', 'resolution', 'seqres', 'updates']
            for file_type in tqdm(file_types, unit='item'):
                result = pdbd.download(file_type=file_type)
                if not result:
                    logger.error(f'Failed to download file_type: \"{file_type}\"')
                    sys.exit(1)
            print()
    elif mode == 'rsync_pdb':
        with clean_exit(callback=pdbd.clean_unsuccessful):
            logger.info('Syncing protein structures in the \'pdb\' format...')
            result = pdbd.rsync_pdb_mirror(format='pdb')
            if result != 0:
                logger.error('Failed to RSYNC with the PDB server')
                sys.exit(1)
    elif mode == 'rsync_cif':
        with clean_exit(callback=pdbd.clean_unsuccessful):
            logger.info('Syncing protein structures in the \'mmCIF\' format...')
            result = pdbd.rsync_pdb_mirror(format='mmCIF')
            print()
            if result != 0:
                logger.error('Failed to RSYNC with the PDB server')
                sys.exit(1)
    pdbd.remove_lock()

def install_plugins(args):
    pass

def main(args):

    # Load config
    args.remote_source = load_remote_source(args.mirror)

    # Override config options if custom urls were provided
    if args.ftp_url:
        args.remote_source['url'] = args.ftp_url
    if args.rsync_url:
        args.remote_source['rsync_url'] = args.rsync_url
    if args.rsync_opts:
        args.remote_source['rsync_opts'] = args.rsync_opts
    if args.clust_url:
        args.remote_source['clust']['url'] = args.clust_url

    try:
        pdbv = PDBVersioneer(db_path=args.db_path, config=args.remote_source)
        args.current_remote_version = pdbv.current_remote_version
    except (socket.timeout, ftplib.error_temp):
        logger.error('Could not connect to the FTP server. Please check the URL details:')
        url = args.remote_source['ftp_url']
        logger.error(f'ftp://{url}')
        sys.exit(1)
    except ValueError:
        logger.error('No valid PDB data found in the remote source. Please check the URL details:')
        url = args.remote_source['ftp_url']
        logger.error(f'ftp://{url}')
        sys.exit(1)

    # Check if directory already exists - won't ask this question if run is restarted because of cancelling / failure
    if os.path.exists(args.db_path) and os.path.isdir(args.db_path) and not pdbv.check_init():
        if len(os.listdir(args.db_path)):
            logger.warning(f'Specified directory \'{args.db_path}\'exists and is not empty!')
            print()
    else:
        create_directory(args.db_path)

    # localpdb is not set up - start from scratch
    if pdbv.current_local_version is None:
        if args.update:
            logger.error(f'localpdb is not set up in the directory: \'{args.db_path}\'!')
            sys.exit(1)
        print()
        print(f'This script will setup the localpdb database in the directory:\n{args.db_path}')
        print()

        # Create directories
        dirs = ['data', 'mirror', 'mirror/pdb', 'mirror/mmCIF', 'logs', f'data/{args.current_remote_version}']
        for _dir in dirs:
            create_directory('{}/{}'.format(args.db_path, _dir))
        pdbv.init()

        # Download PDB files
        logger.debug(f'Using \'{args.mirror}\' mirror for downloads.')
        logger.debug(f'Current remote PDB version is \'{args.current_remote_version}\'')
        logger.info(f'Downloading release data for the PDB version: \'{args.current_remote_version}\'...')
        download(args, mode='files')

        # RSYNC PDB structures
        if any((args.fetch_pdb, args.fetch_cif)):
            logger.info(f'Downloading protein structures...')
            logger.info('(This can take around 2-4 hours depending on the selected mirror.'
                        ' If the run will be stopped it can be restarted later.)')
            print()
        if args.fetch_pdb:
            download(args, mode='rsync_pdb', clean=False)
            print()
        if args.fetch_cif:
            download(args, mode='rsync_cif', clean=False)
            print()

        # Finally - setup config, log and report success
        pdbv.update_logs(first=True)
        conf_dict = {'init_ver': args.current_remote_version, 'struct_mirror': {'pdb': args.fetch_pdb,
                                                                                'pdb_init_ver': args.current_remote_version if args.fetch_pdb else None,
                                                                                'cif': args.fetch_cif,
                                                                                'cif_init_ver': args.current_remote_version if args.fetch_cif else None}}
        config = Config(args.db_path / 'config.yml', init=True)
        config.data = conf_dict
        config.commit()
        print()
        logger.info(f'Successfully set up localpdb in \'{args.db_path}\'')
        # Move log file to localpdb dir
        logging.shutdown()
        log_path = args.db_path / 'logs'
        shutil.move(fn_log, log_path)

    # localpdb is set up and up to date
    elif args.current_remote_version == pdbv.current_local_version:
        config = Config(args.db_path / 'config.yml')
        # check if structure sync is requested on the already set up localpdb

        if not config.data['struct_mirror']['pdb'] and args.fetch_pdb and not args.update:
            download(args, mode='rsync_pdb', clean=False)
            print()
            config.data['struct_mirror']['pdb'] = True
            config.data['struct_mirror']['pdb_init_ver'] = args.current_remote_version
        if not config.data['struct_mirror']['cif'] and args.fetch_cif and not args.update:
            download(args, mode='rsync_cif', clean=False)
            print()
            config.data['struct_mirror']['cif'] = True
            config.data['struct_mirror']['cif_init_ver'] = args.current_remote_version
        else:
            logger.info(f'localpdb is up to date and set up in the directory \'{args.db_path}\'.')
        config.commit()

    # localpdb is set up but there's a newer remote version available
    elif args.current_remote_version > pdbv.current_local_version:
        if args.update:
            logger.info(
                'localpdb is {} update(s) behind with the remote source, updating to version {}...'.format(
                    len(pdbv.missing_remote_versions), pdbv.current_remote_version))
            print()
            config = Config(args.db_path / 'config.yml').data
            # Create directories
            dirs = ['data', 'mirror', 'mirror/pdb', 'mirror/mmCIF', 'logs', f'data/{args.current_remote_version}']
            for _dir in dirs:
                create_directory('{}/{}'.format(args.db_path, _dir))

            # Download PDB files
            logger.debug(f'Using \'{args.mirror}\' mirror for downloads.')
            download(args, mode='files')
            if not any([config['struct_mirror']['pdb'], config['struct_mirror']['cif']]):
                logger.debug('Skipping structure files syncing...')
            if config['struct_mirror']['pdb']:
                download(args, mode='rsync_pdb', clean=True)
            if config['struct_mirror']['cif']:
                download(args, mode='rsync_cif', clean=True)

            pdbv.update_logs()
            logger.info(
                f'Successfully updated localpdb in \'{args.db_path}\' to version \'{pdbv.current_remote_version}\'!')
            # Move log file to localpdb dir
            logging.shutdown()
            log_path = args.db_path / 'logs'
            shutil.move(fn_log, log_path)
        else:
            logger.info(
                f'localpdb is set up in the directory \'{args.db_path}\' but is not up to date. Consider an update!')
            if any([args.fetch_pdb, args.fetch_cif]):
                logger.warning('Structure files cannot be synced when local version is outdated. Update localpdb first.')

if __name__ == "__main__":
    # Get commandline arguments
    arg = get_params()

    # Setup logging
    fn_log, handlers = setup_logging_handlers(tmp_path=arg.tmp_path)
    logging.basicConfig(level=logging.DEBUG, handlers=handlers, datefmt='%Y-%m-%d %H:%M:%S')
    logger = logging.getLogger(__name__)

    # Run main
    main(arg)
